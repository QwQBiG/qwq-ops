# qwq-ops Platform ğŸš€

[![Kubernetes](https://img.shields.io/badge/Kubernetes-v1.28+-326ce5.svg)](https://kubernetes.io/)
[![AIOps](https://img.shields.io/badge/AIOps-K8sGPT%20%2B%20Ollama-ff69b4.svg)](https://k8sgpt.ai/)
[![GitOps](https://img.shields.io/badge/GitOps-ArgoCD-orange.svg)](https://argoproj.github.io/cd/)

**qwq-ops** æ˜¯ä¸€ä¸ªåŸºäºæ ‡å‡† Kubernetes (Kubeadm) æ„å»ºçš„ä¸‹ä¸€ä»£äº‘åŸç”Ÿ AIOps åº•åº§ã€‚
æœ¬é¡¹ç›®æ—¨åœ¨å•èŠ‚ç‚¹è£¸é‡‘å±æœåŠ¡å™¨ï¼ˆUbuntu 22.04ï¼‰ä¸Šï¼Œä»é›¶æ­å»ºä¸€å¥—é›†æˆäº†**å¯è§‚æµ‹æ€§**ã€**GitOps** å’Œ **æœ¬åœ°ç§æœ‰åŒ– AI è¿ç»´èƒ½åŠ›** çš„ç”Ÿäº§çº§å¹³å°ã€‚

---

# AIOps å¹³å°éƒ¨ç½²æŒ‡å—

åŸºäº Kubernetes (Kubeadm) çš„ç°ä»£åŒ– AIOps å¹³å°ï¼Œé›†æˆå®Œæ•´çš„å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰èƒ½åŠ›å’Œ AI è¿ç»´èƒ½åŠ›ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†å¹¶è¿›å…¥ç›®å½•
git clone https://github.com/QwQBiG/qwq-ops.git
cd qwq-ops

# 2. æ·»åŠ æ‰§è¡Œæƒé™
chmod +x *.sh

# 3. å®‰è£… Helm (å¦‚æœæœªå®‰è£…)
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# 4. ä¸€é”®éƒ¨ç½² (æŒ‰é¡ºåºæ‰§è¡Œ)
sudo ./01_init_k8s.sh              # åˆå§‹åŒ– K8s é›†ç¾¤ (~10åˆ†é’Ÿ)
sudo ./02_setup_storage.sh         # é…ç½®å­˜å‚¨ç±» (~1åˆ†é’Ÿ)
sudo ./03_deploy_stack.sh          # éƒ¨ç½² AIOps æŠ€æœ¯æ ˆ (~15åˆ†é’Ÿ)
kubectl apply -f k8sgpt_integration.yaml  # åº”ç”¨é›†æˆé…ç½®

# 5. éªŒè¯éƒ¨ç½²
./verify_deployment.sh
```

### å›½å†…ç½‘ç»œä¸€é”®éƒ¨ç½²

```bash
# ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒæºåˆå§‹åŒ–é›†ç¾¤
sudo ./01_init_k8s.sh --use-aliyun-mirror
sudo ./02_setup_storage.sh
sudo ./03_deploy_stack.sh --model qwen:1.8b  # ä½¿ç”¨ä¸­æ–‡å‹å¥½çš„å°æ¨¡å‹
kubectl apply -f k8sgpt_integration.yaml
./verify_deployment.sh
```

## ğŸ“‹ éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹éƒ¨ç½²å‰ï¼Œè¯·ç¡®è®¤ä»¥ä¸‹æ¡ä»¶ï¼š

```bash
# 1. æ£€æŸ¥æ“ä½œç³»ç»Ÿç‰ˆæœ¬
cat /etc/os-release | grep -E "^(NAME|VERSION)="
# æœŸæœ›è¾“å‡º: Ubuntu 22.04 LTS

# 2. æ£€æŸ¥ CPU æ ¸å¿ƒæ•° (æœ€ä½ 4 æ ¸)
nproc
# æœŸæœ›è¾“å‡º: >= 4

# 3. æ£€æŸ¥å†…å­˜å¤§å° (æœ€ä½ 8GBï¼Œæ¨è 16GB)
free -h | grep Mem
# æœŸæœ›è¾“å‡º: æ€»å†…å­˜ >= 8Gi

# 4. æ£€æŸ¥ç£ç›˜ç©ºé—´ (æœ€ä½ 50GB)
df -h /
# æœŸæœ›è¾“å‡º: å¯ç”¨ç©ºé—´ >= 50G

# 5. æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
ping -c 3 google.com || ping -c 3 baidu.com
# æœŸæœ›è¾“å‡º: èƒ½å¤Ÿ ping é€š

# 6. æ£€æŸ¥æ˜¯å¦æœ‰ root æƒé™
sudo whoami
# æœŸæœ›è¾“å‡º: root
```

## ğŸ—ï¸ å¹³å°æ¶æ„

```mermaid
flowchart TB
    subgraph AI["ğŸ¤– AI è¿ç»´å±‚"]
        K8SGPT[K8sGPT<br/>æ•…éšœè¯Šæ–­]
        OLLAMA[Ollama<br/>LLM æ¨ç†]
        K8SGPT -->|è°ƒç”¨ AI| OLLAMA
    end

    subgraph OBS["ğŸ“Š å¯è§‚æµ‹æ€§å±‚"]
        VM[VictoriaMetrics<br/>æŒ‡æ ‡å­˜å‚¨]
        LOKI[Loki + Promtail<br/>æ—¥å¿—å­˜å‚¨]
        GRAFANA[Grafana<br/>å¯è§†åŒ–ä»ªè¡¨ç›˜]
        VM --> GRAFANA
        LOKI --> GRAFANA
    end

    subgraph GITOPS["ğŸ”„ GitOps å±‚"]
        ARGOCD[Argo CD<br/>æŒç»­éƒ¨ç½²]
    end

    subgraph INFRA["âš™ï¸ åŸºç¡€è®¾æ–½å±‚"]
        K8S[Kubernetes<br/>Kubeadm]
        CALICO[Calico CNI<br/>Pod ç½‘ç»œ]
        STORAGE[Local Path Provisioner<br/>æœ¬åœ°å­˜å‚¨]
    end

    AI --> OBS
    OBS --> GITOPS
    GITOPS --> INFRA
    K8SGPT -.->|ç›‘æ§é›†ç¾¤| K8S
```

### æ•°æ®æµå‘

```mermaid
flowchart LR
    subgraph æ•°æ®é‡‡é›†
        APP[åº”ç”¨ Pod] -->|æ—¥å¿—| PROMTAIL[Promtail]
        APP -->|æŒ‡æ ‡| VMAGENT[VMAgent]
    end

    subgraph æ•°æ®å­˜å‚¨
        PROMTAIL --> LOKI[(Loki)]
        VMAGENT --> VM[(VictoriaMetrics)]
    end

    subgraph å¯è§†åŒ–
        LOKI --> GRAFANA[Grafana]
        VM --> GRAFANA
    end

    subgraph AIè¯Šæ–­
        K8S[K8s API] --> K8SGPT[K8sGPT]
        K8SGPT --> OLLAMA[Ollama]
        OLLAMA -->|åˆ†æç»“æœ| K8SGPT
    end
```

## ğŸ“¦ ç»„ä»¶æ¸…å•

| ç»„ä»¶ | ç‰ˆæœ¬ | å‘½åç©ºé—´ | ç”¨é€” |
|------|------|----------|------|
| Kubernetes | 1.28+ | - | å®¹å™¨ç¼–æ’å¹³å° |
| Calico | v3.26.4 | calico-system | ç½‘ç»œæ’ä»¶ (CNI) |
| Local Path Provisioner | v0.0.26 | local-path-storage | æœ¬åœ°å­˜å‚¨ |
| VictoriaMetrics | latest | monitoring | æŒ‡æ ‡å­˜å‚¨ |
| Grafana | latest | monitoring | å¯è§†åŒ–ä»ªè¡¨ç›˜ |
| Loki | latest | logging | æ—¥å¿—èšåˆ |
| Promtail | latest | logging | æ—¥å¿—é‡‡é›† |
| Argo CD | latest | argocd | GitOps æŒç»­éƒ¨ç½² |
| Ollama | latest | ai | LLM æ¨ç†å¼•æ“ |
| K8sGPT | latest | k8sgpt | AI æ•…éšœè¯Šæ–­ |

## ğŸ’» ç¡¬ä»¶è¦æ±‚

| é…ç½®é¡¹ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® | è¯´æ˜ |
|--------|----------|----------|------|
| CPU | 4 vCPU | 8 vCPU | AI æ¨ç†éœ€è¦è¾ƒå¤š CPU |
| å†…å­˜ | 8 GB | 16 GB | LLM æ¨¡å‹éœ€è¦å¤§é‡å†…å­˜ |
| ç£ç›˜ | 50 GB | 100 GB SSD | æ—¥å¿—å’ŒæŒ‡æ ‡å­˜å‚¨ |
| ç½‘ç»œ | 1 Gbps | 1 Gbps | é•œåƒæ‹‰å–å’ŒæœåŠ¡é€šä¿¡ |

## ğŸ“ è¯¦ç»†éƒ¨ç½²æ­¥éª¤

### æ­¥éª¤ 1: åˆå§‹åŒ– Kubernetes é›†ç¾¤

```bash
sudo ./01_init_k8s.sh
# æˆ–ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒ (å›½å†…æ¨è)
sudo ./01_init_k8s.sh --use-aliyun-mirror
```

**æ‰§è¡Œå†…å®¹:**
- âœ… ç¦ç”¨ swap å¹¶æŒä¹…åŒ–é…ç½®
- âœ… åŠ è½½ overlay å’Œ br_netfilter å†…æ ¸æ¨¡å—
- âœ… é…ç½® sysctl ç½‘ç»œå‚æ•°
- âœ… å®‰è£… containerd å®¹å™¨è¿è¡Œæ—¶
- âœ… å®‰è£… kubeadm, kubelet, kubectl
- âœ… åˆå§‹åŒ–å•èŠ‚ç‚¹ K8s é›†ç¾¤
- âœ… å®‰è£… Calico CNI ç½‘ç»œæ’ä»¶
- âœ… ç§»é™¤ control-plane æ±¡ç‚¹

**é¢„è®¡è€—æ—¶:** 5-15 åˆ†é’Ÿ (å–å†³äºç½‘ç»œé€Ÿåº¦)

**éªŒè¯:**
```bash
kubectl get nodes
# æœŸæœ›è¾“å‡º: èŠ‚ç‚¹çŠ¶æ€ä¸º Ready

kubectl get pods -n calico-system
# æœŸæœ›è¾“å‡º: æ‰€æœ‰ Pod çŠ¶æ€ä¸º Running
```

### æ­¥éª¤ 2: é…ç½®å­˜å‚¨ç±»

```bash
sudo ./02_setup_storage.sh
```

**æ‰§è¡Œå†…å®¹:**
- âœ… å®‰è£… Local Path Provisioner
- âœ… è®¾ç½®é»˜è®¤ StorageClass

**é¢„è®¡è€—æ—¶:** 1-2 åˆ†é’Ÿ

**éªŒè¯:**
```bash
kubectl get sc
# æœŸæœ›è¾“å‡º: local-path (default)
```

### æ­¥éª¤ 3: éƒ¨ç½² AIOps æŠ€æœ¯æ ˆ

```bash
sudo ./03_deploy_stack.sh
# æˆ–æŒ‡å®šè½»é‡æ¨¡å‹ (å†…å­˜ â‰¤8GB æ¨è)
sudo ./03_deploy_stack.sh --model tinyllama
```

**æ‰§è¡Œå†…å®¹:**
- âœ… é…ç½® Helm ä»“åº“
- âœ… éƒ¨ç½² VictoriaMetrics Stack (monitoring å‘½åç©ºé—´)
- âœ… éƒ¨ç½² Loki Stack (logging å‘½åç©ºé—´)
- âœ… éƒ¨ç½² Argo CD (argocd å‘½åç©ºé—´)
- âœ… éƒ¨ç½² Ollama (ai å‘½åç©ºé—´)
- âœ… éƒ¨ç½² K8sGPT Operator (k8sgpt å‘½åç©ºé—´)

**é¢„è®¡è€—æ—¶:** 10-20 åˆ†é’Ÿ (å–å†³äºç½‘ç»œé€Ÿåº¦å’Œé•œåƒæ‹‰å–)

**éªŒè¯:**
```bash
helm list -A
# æœŸæœ›è¾“å‡º: 5 ä¸ª Helm release éƒ½æ˜¯ deployed çŠ¶æ€
```

### æ­¥éª¤ 4: åº”ç”¨é›†æˆé…ç½®

```bash
kubectl apply -f k8sgpt_integration.yaml
```

**æ‰§è¡Œå†…å®¹:**
- âœ… åˆ›å»º K8sGPT CR (è¿æ¥ Ollama)
- âœ… åˆ›å»º ServiceMonitor (æŒ‡æ ‡é‡‡é›†)
- âœ… åˆ›å»º Grafana æ•°æ®æº ConfigMaps

**éªŒè¯:**
```bash
kubectl get k8sgpt -n k8sgpt
# æœŸæœ›è¾“å‡º: k8sgpt èµ„æºå·²åˆ›å»º
```

### æ­¥éª¤ 5: éªŒè¯éƒ¨ç½²

```bash
./verify_deployment.sh
```

æ­¤è„šæœ¬ä¼šæ£€æŸ¥æ‰€æœ‰ç»„ä»¶çŠ¶æ€å¹¶è¾“å‡º:
- èŠ‚ç‚¹çŠ¶æ€
- StorageClass é…ç½®
- å„å‘½åç©ºé—´ Pod çŠ¶æ€
- Helm release çŠ¶æ€
- è®¿é—®ä¿¡æ¯å’Œå¯†ç è·å–å‘½ä»¤

## ğŸŒ è®¿é—®ç»„ä»¶

### Grafana (ç›‘æ§ä»ªè¡¨ç›˜)

```bash
# ç«¯å£è½¬å‘ (å‰å°è¿è¡Œ)
kubectl port-forward -n monitoring svc/victoria-metrics-grafana 3000:80

# æˆ–åå°è¿è¡Œ
kubectl port-forward -n monitoring svc/victoria-metrics-grafana 3000:80 &

# è·å–å¯†ç 
kubectl get secret -n monitoring victoria-metrics-grafana \
  -o jsonpath="{.data.admin-password}" | base64 -d; echo

# è®¿é—®åœ°å€: http://localhost:3000
# ç”¨æˆ·å: admin
# å¯†ç : ä¸Šé¢å‘½ä»¤è¾“å‡ºçš„å¯†ç  (é»˜è®¤å¯èƒ½æ˜¯ admin)
```

### Argo CD (GitOps)

```bash
# ç«¯å£è½¬å‘
kubectl port-forward -n argocd svc/argocd-server 8080:443 &

# è·å–å¯†ç 
kubectl get secret -n argocd argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d; echo

# è®¿é—®åœ°å€: https://localhost:8080
# ç”¨æˆ·å: admin
```

### VictoriaMetrics (æŒ‡æ ‡æŸ¥è¯¢)

```bash
# ç«¯å£è½¬å‘
kubectl port-forward -n monitoring \
  svc/vmsingle-victoria-metrics-victoria-metrics-k8s-stack 8428:8428 &

# è®¿é—®åœ°å€: http://localhost:8428/vmui
```

### Ollama API (AI æ¨ç†)

```bash
# ç«¯å£è½¬å‘
kubectl port-forward -n ai svc/ollama 11434:11434 &

# æµ‹è¯• API
curl http://localhost:11434/api/tags

# æµ‹è¯•å¯¹è¯
curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "Hello, how are you?",
  "stream": false
}'
```

### è¿œç¨‹è®¿é—®

å¦‚æœéœ€è¦ä»å…¶ä»–æœºå™¨è®¿é—®ï¼Œæ·»åŠ  `--address 0.0.0.0`:

```bash
# å…è®¸è¿œç¨‹è®¿é—® Grafana
kubectl port-forward -n monitoring svc/victoria-metrics-grafana 3000:80 --address 0.0.0.0 &

# ç„¶åé€šè¿‡ http://<æœåŠ¡å™¨IP>:3000 è®¿é—®
```

## ğŸ”§ K8sGPT AI è¯Šæ–­ä½¿ç”¨

### æŸ¥çœ‹è¯Šæ–­ç»“æœ

```bash
# æŸ¥çœ‹ K8sGPT çŠ¶æ€
kubectl get k8sgpt -n k8sgpt -o yaml

# æŸ¥çœ‹åˆ†æç»“æœ
kubectl get results -n k8sgpt

# æŸ¥çœ‹è¯¦ç»†åˆ†æ
kubectl describe results -n k8sgpt
```

### æµ‹è¯• Ollama è¿æ¥

```bash
# åœ¨é›†ç¾¤å†…æµ‹è¯•
kubectl run test-ollama --rm -it --image=curlimages/curl --restart=Never -- \
  curl -s http://ollama.ai.svc.cluster.local:11434/api/tags

# æ£€æŸ¥å·²åŠ è½½çš„æ¨¡å‹
kubectl exec -n ai deploy/ollama -- ollama list

# æ‰‹åŠ¨æ‹‰å–æ¨¡å‹ (å¦‚æœè‡ªåŠ¨æ‹‰å–å¤±è´¥)
kubectl exec -n ai deploy/ollama -- ollama pull llama3
```

## ğŸ‡¨ğŸ‡³ å›½å†…ç½‘ç»œä¼˜åŒ–

### 1. ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒåˆå§‹åŒ–é›†ç¾¤

```bash
sudo ./01_init_k8s.sh --use-aliyun-mirror
```

### 2. é…ç½® containerd é•œåƒåŠ é€Ÿ

```bash
# ç¼–è¾‘ containerd é…ç½®
sudo vim /etc/containerd/config.toml

# åœ¨ [plugins."io.containerd.grpc.v1.cri".registry.mirrors] ä¸‹æ·»åŠ :
[plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
  endpoint = ["https://mirror.ccs.tencentyun.com", "https://docker.mirrors.ustc.edu.cn"]

[plugins."io.containerd.grpc.v1.cri".registry.mirrors."quay.io"]
  endpoint = ["https://quay.mirrors.ustc.edu.cn"]

[plugins."io.containerd.grpc.v1.cri".registry.mirrors."gcr.io"]
  endpoint = ["https://gcr.mirrors.ustc.edu.cn"]

# é‡å¯ containerd
sudo systemctl restart containerd
```

### 3. ä½¿ç”¨ä»£ç† (å¦‚æœæœ‰)

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export HTTP_PROXY="http://proxy:port"
export HTTPS_PROXY="http://proxy:port"
export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16"

# ç„¶åæ‰§è¡Œéƒ¨ç½²è„šæœ¬
sudo -E ./01_init_k8s.sh
```

## ğŸ’¾ å†…å­˜ä¼˜åŒ–

### æ¨¡å‹é€‰æ‹©æŒ‡å—

| æ¨¡å‹ | å†…å­˜éœ€æ±‚ | æ¨ç†é€Ÿåº¦ | ä¸­æ–‡æ”¯æŒ | é€‚ç”¨åœºæ™¯ |
|------|----------|----------|----------|----------|
| llama3 | ~4GB | ä¸­ç­‰ | ä¸€èˆ¬ | æ¨èï¼Œå¹³è¡¡æ€§èƒ½å’Œè´¨é‡ |
| gemma:2b | ~2GB | å¿« | ä¸€èˆ¬ | å†…å­˜å—é™ç¯å¢ƒ |
| qwen:1.8b | ~2GB | å¿« | å¥½ | ä¸­æ–‡ç¯å¢ƒæ¨è |
| tinyllama | ~1GB | æœ€å¿« | å·® | æä½å†…å­˜ç¯å¢ƒ |

### ä½å†…å­˜éƒ¨ç½² (â‰¤8GB)

```bash
# ä½¿ç”¨æœ€å°æ¨¡å‹
sudo ./03_deploy_stack.sh --model tinyllama

# æˆ–è€…éƒ¨ç½²åæ‰‹åŠ¨åˆ‡æ¢æ¨¡å‹
kubectl exec -n ai deploy/ollama -- ollama pull tinyllama
kubectl exec -n ai deploy/ollama -- ollama rm llama3  # åˆ é™¤å¤§æ¨¡å‹é‡Šæ”¾ç©ºé—´
```

## â“ å¸¸è§é—®é¢˜æ’æŸ¥

### 1. Pod ä¸€ç›´ Pending

```bash
# æ£€æŸ¥åŸå› 
kubectl describe pod <pod-name> -n <namespace>

# å¸¸è§åŸå› : æ²¡æœ‰é»˜è®¤ StorageClass
kubectl get sc
kubectl patch storageclass local-path \
  -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

### 2. é›†ç¾¤åˆå§‹åŒ–å¤±è´¥

```bash
# å®Œå…¨é‡ç½®
sudo kubeadm reset -f
sudo rm -rf /etc/cni/net.d/* ~/.kube /var/lib/etcd
sudo iptables -F && sudo iptables -t nat -F && sudo iptables -t mangle -F

# é‡æ–°åˆå§‹åŒ–
sudo ./01_init_k8s.sh
```

### 3. é•œåƒæ‹‰å–å¤±è´¥

```bash
# æŸ¥çœ‹å¤±è´¥çš„ Pod
kubectl get pods -A | grep -v Running

# æŸ¥çœ‹å…·ä½“é”™è¯¯
kubectl describe pod <pod-name> -n <namespace>

# æ‰‹åŠ¨æ‹‰å–é•œåƒ (åœ¨èŠ‚ç‚¹ä¸Š)
sudo crictl pull <image-name>
```

### 4. Helm å®‰è£…è¶…æ—¶

```bash
# å¢åŠ è¶…æ—¶æ—¶é—´é‡è¯•
helm upgrade --install <release> <chart> --timeout 30m --wait

# æˆ–è€…ä¸ç­‰å¾…ç›´æ¥å®‰è£…
helm upgrade --install <release> <chart> --timeout 30m
```

### 5. Ollama æ¨¡å‹æ‹‰å–æ…¢

```bash
# æŸ¥çœ‹æ‹‰å–è¿›åº¦
kubectl logs -n ai deploy/ollama -f

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
kubectl exec -n ai deploy/ollama -- ollama pull tinyllama
```

### 6. æŸ¥çœ‹æ‰€æœ‰ç»„ä»¶çŠ¶æ€

```bash
# ä¸€é”®æŸ¥çœ‹
./verify_deployment.sh

# æˆ–æ‰‹åŠ¨æ£€æŸ¥
kubectl get pods -A
kubectl get events -A --sort-by='.lastTimestamp' | tail -30
```

## ğŸ—‘ï¸ å¸è½½æŒ‡å—

### å¸è½½ AIOps ç»„ä»¶ (ä¿ç•™ K8s é›†ç¾¤)

```bash
# åˆ é™¤é›†æˆé…ç½®
kubectl delete -f k8sgpt_integration.yaml

# åˆ é™¤ Helm releases
helm uninstall k8sgpt-operator -n k8sgpt
helm uninstall ollama -n ai
helm uninstall argocd -n argocd
helm uninstall loki -n logging
helm uninstall victoria-metrics -n monitoring

# åˆ é™¤å‘½åç©ºé—´
kubectl delete namespace k8sgpt ai argocd logging monitoring

# åˆ é™¤ Local Path Provisioner
kubectl delete -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.26/deploy/local-path-storage.yaml
```

### å®Œå…¨å¸è½½ (åŒ…æ‹¬ K8s é›†ç¾¤)

```bash
# é‡ç½® kubeadm
sudo kubeadm reset -f

# æ¸…ç†é…ç½®
sudo rm -rf /etc/cni/net.d/* ~/.kube /var/lib/etcd /etc/kubernetes

# æ¸…ç† iptables
sudo iptables -F && sudo iptables -t nat -F && sudo iptables -t mangle -F

# åœæ­¢æœåŠ¡
sudo systemctl stop kubelet containerd
sudo systemctl disable kubelet containerd

# å¸è½½è½¯ä»¶åŒ… (å¯é€‰)
sudo apt-mark unhold kubelet kubeadm kubectl
sudo apt-get remove -y kubelet kubeadm kubectl containerd.io
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [Kubernetes å®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
- [Calico æ–‡æ¡£](https://docs.tigera.io/calico/latest/about/)
- [VictoriaMetrics æ–‡æ¡£](https://docs.victoriametrics.com/)
- [Grafana Loki æ–‡æ¡£](https://grafana.com/docs/loki/latest/)
- [Argo CD æ–‡æ¡£](https://argo-cd.readthedocs.io/)
- [Ollama æ–‡æ¡£](https://ollama.ai/)
- [K8sGPT æ–‡æ¡£](https://docs.k8sgpt.ai/)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œæµ‹è¯•ä½¿ç”¨ã€‚å„ç»„ä»¶éµå¾ªå…¶å„è‡ªçš„å¼€æºè®¸å¯è¯ã€‚
